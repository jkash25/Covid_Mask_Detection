{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w4MS03qGGYYg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INIT_LR = 1e-4\n",
        "EPOCHS = 20\n",
        "BS = 32"
      ],
      "metadata": {
        "id": "dFsjdFnXGoDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading images...\")\n",
        "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
        "data = []\n",
        "labels = []\n",
        "for imagePath in imagePaths:\n",
        "\tlabel = imagePath.split(os.path.sep)[-2]\n",
        "\timage = load_img(imagePath, target_size=(224, 224))\n",
        "\timage = img_to_array(image)\n",
        "\timage = preprocess_input(image)\n",
        "\tdata.append(image)\n",
        "\tlabels.append(label)\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "e_zPFtqPGo2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "\ttest_size=0.20, stratify=labels, random_state=42)\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "metadata": {
        "id": "qUq3usJ4IPpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        "\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False"
      ],
      "metadata": {
        "id": "CCZ53JNnJLrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "\tmetrics=[\"accuracy\"])\n",
        "print(\"[INFO] training head...\")\n",
        "H = model.fit(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tvalidation_steps=len(testX) // BS,\n",
        "\tepochs=EPOCHS)"
      ],
      "metadata": {
        "id": "0v2Wczv0JUxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] evaluating network...\")\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=lb.classes_))\n",
        "print(\"[INFO] saving mask detector model...\")\n",
        "model.save(args[\"model\"], save_format=\"h5\")"
      ],
      "metadata": {
        "id": "-iWA84c9JWf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(args[\"plot\"])"
      ],
      "metadata": {
        "id": "ibEuI7DhJbjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "rn8XBMQxJmEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ap = argparse.ArgumentParser()\n",
        "ap.add_argument(\"-i\", \"--image\", required=True,\n",
        "\thelp=\"path to input image\")\n",
        "ap.add_argument(\"-f\", \"--face\", type=str,\n",
        "\tdefault=\"face_detector\",\n",
        "\thelp=\"path to face detector model directory\")\n",
        "ap.add_argument(\"-m\", \"--model\", type=str,\n",
        "\tdefault=\"mask_detector.model\",\n",
        "\thelp=\"path to trained face mask detector model\")\n",
        "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
        "\thelp=\"minimum probability to filter weak detections\")\n",
        "args = vars(ap.parse_args())"
      ],
      "metadata": {
        "id": "dnMRDlikJn-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading face detector model...\")\n",
        "prototxtPath = os.path.sep.join([args[\"face\"], \"deploy.prototxt\"])\n",
        "weightsPath = os.path.sep.join([args[\"face\"],\n",
        "\t\"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
        "net = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
        "print(\"[INFO] loading face mask detector model...\")\n",
        "model = load_model(args[\"model\"])"
      ],
      "metadata": {
        "id": "6qgIZdIzJqlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread(args[\"image\"])\n",
        "orig = image.copy()\n",
        "(h, w) = image.shape[:2]\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "\t(104.0, 177.0, 123.0))\n",
        "print(\"[INFO] computing face detections...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()"
      ],
      "metadata": {
        "id": "5ac0Xi9SJttA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, detections.shape[2]):\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\tif confidence > args[\"confidence\"]:\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))"
      ],
      "metadata": {
        "id": "lZOPCInhJyx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face = image[startY:endY, startX:endX]\n",
        "face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "face = cv2.resize(face, (224, 224))\n",
        "face = img_to_array(face)\n",
        "face = preprocess_input(face)\n",
        "face = np.expand_dims(face, axis=0)\n",
        "(mask, withoutMask) = model.predict(face)[0]"
      ],
      "metadata": {
        "id": "V5GUpozCJ-Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = \"Mask\" if mask > withoutMask else \"No Mask\"\n",
        "color = (0, 255, 0) if label == \"Mask\" else (0, 0, 255)\n",
        "label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "cv2.putText(image, label, (startX, startY - 10),\n",
        "cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "cv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "cv2.imshow(\"Output\", image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "b44EqivtKBjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X8PFwg_9KYxB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}